{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pymrmr\n",
    "import random\n",
    "import pandas\n",
    "import roc_utils as ru\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score,classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from ReliefF import ReliefF\n",
    "from itertools import cycle\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot\n",
    "\n",
    "numpy.set_printoptions(precision=2)\n",
    "NCPU=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiCollinearityEliminator(dataframe, threshold):\n",
    "    variables = set(dataframe.columns)\n",
    "    high_correlated_variables = set()\n",
    "    for i in variables:\n",
    "        for j in (variables - high_correlated_variables):\n",
    "            if i == j:\n",
    "                continue\n",
    "            else:\n",
    "                rank, p_value = stats.spearmanr(dataframe[i], dataframe[j])\n",
    "                if abs(rank) >= threshold:\n",
    "                    high_correlated_variables.add(i)\n",
    "                    break\n",
    "    df = dataframe.drop(dataframe[list(high_correlated_variables)], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Defining function for confusion matrix plot\n",
    "n_classes=2\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=n_classes,dataset='Test',\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = ''  \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')  \n",
    "    #Print Confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    if normalize:\n",
    "        fig.savefig(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_{dataset}_NCM.jpg',\n",
    "               dpi=300, facecolor='w', edgecolor='w',\n",
    "               format='jpg', transparent=False, bbox_inches=None, pad_inches=0.1)\n",
    "    else:\n",
    "        fig.savefig(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_{dataset}_CM.jpg',\n",
    "               dpi=300, facecolor='w', edgecolor='w',\n",
    "               format='jpg', transparent=False, bbox_inches=None, pad_inches=0.1)\n",
    "    plt.close()\n",
    "    return ax  \n",
    "\n",
    "\n",
    "\n",
    "def roc_plot(y_true,y_score,dataset='Train'):\n",
    "        n_samples = 1000\n",
    "        ru.plot_roc_bootstrap(X=y_score, y=y_true, pos_label=1,\n",
    "                      n_bootstrap=n_samples,show_ti=True,show_ci=True,\n",
    "                      title='');\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score,pos_label=1)\n",
    "        roc_auc= auc(fpr, tpr)\n",
    "        # First aggregate all false positive rates\n",
    "\n",
    "        # # Plot all ROC curves\n",
    "        # lw=2\n",
    "        # plt.figure()\n",
    "        # plt.plot(\n",
    "        #     fpr,\n",
    "        #     tpr,\n",
    "        #     label=\"AUC = {0:0.2f}\".format(roc_auc),\n",
    "        #     color=\"deeppink\",\n",
    "        #     linestyle=\":\",\n",
    "        #     linewidth=4,\n",
    "        # )\n",
    "\n",
    "        # plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "        # plt.xlim([0.0, 1.0])\n",
    "        # plt.ylim([0.0, 1.05])\n",
    "        # plt.xlabel(\"False Positive Rate\")\n",
    "        # plt.ylabel(\"True Positive Rate\")\n",
    "        pyplot.savefig(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_{dataset}_ROC.jpg', dpi=600, facecolor='w', edgecolor='w',\n",
    "                    orientation='portrait', format='jpg', transparent=False, bbox_inches=None, pad_inches=0.1)\n",
    "        #plt.show()\n",
    "        pyplot.close()\n",
    "        return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA-PSMA_Multicentric(WP).xlsx\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/max/Documents/Classification/Data/WP\")\n",
    "Files_List = glob.glob('*.xlsx')\n",
    "Train_Results_Matrix_all = pandas.DataFrame(columns=['set','model', \"auc\",\"accuracy\",\"precision\",\"recall\",\"f1score\"],\n",
    "                                        index=range(0))\n",
    "Test_Results_Matrix_all = Train_Results_Matrix_all.copy()\n",
    "Validation_Results_Matrix_all = Train_Results_Matrix_all.copy()\n",
    "\n",
    "for file in Files_List:\n",
    "    print(file)\n",
    "    DataSet = pandas.read_excel(file)\n",
    "    n_classes=['GS<=7','GS>7']\n",
    "\n",
    "    #n_classes=['GS=6','GS>=7']\n",
    "    #\n",
    "    # Delete Redundent Columns\n",
    "\n",
    "    # Split DataSet to Train, Test, and Validation based on center\n",
    "    Train_Test_Centers = [1, 2]\n",
    "    Validation_Centers = [3]\n",
    "    Train_Test_DataSet = DataSet.loc[DataSet[\"CENTER\"].isin(Train_Test_Centers)]\n",
    "    Validation_DataSet = DataSet.loc[DataSet[\"CENTER\"].isin(Validation_Centers)]\n",
    " \n",
    "    Train_DataSet, Test_DataSet = train_test_split(Train_Test_DataSet, train_size=0.80, test_size=0.2, stratify=Train_Test_DataSet[\"Label\"])\n",
    "    # Save Train. Test, and Validation Set\n",
    "    Folder = Path(file).stem\n",
    "    Directory = os.getcwd()\n",
    "    if (os.path.exists(os.path.join(Directory, Folder)) is False):\n",
    "        os.mkdir(os.path.join(Directory, Folder))\n",
    "    Train_DataSet.to_csv(f'{Directory}//{Folder}//{Folder}_Train.csv', index=False, header=True)\n",
    "    Test_DataSet.to_csv(f'{Directory}//{Folder}//{Folder}_Test.csv', index=False, header=True)\n",
    "    Validation_DataSet.to_csv(f'{Directory}//{Folder}//{Folder}_Validation.csv', index=False, header=True)\n",
    "\n",
    "    Train_Target_Var = Train_DataSet.loc[:, Train_DataSet.columns == \"Label\"]\n",
    "    Train_Target_Var.index = range(len(Train_Target_Var))\n",
    "    Train_Predictor_Vars = Train_DataSet.loc[:, Train_DataSet.columns.drop(['CENTER', 'Gleason', \"Label\"])]\n",
    "    Train_Predictor_Vars.index = range(len(Train_Predictor_Vars))\n",
    "\n",
    "    Test_Target_Var = Test_DataSet.loc[:, Test_DataSet.columns == \"Label\"]\n",
    "    Test_Target_Var.index = range(len(Test_Target_Var))\n",
    "    Test_Predictor_Vars = Test_DataSet.loc[:, Test_DataSet.columns.drop(['CENTER', 'Gleason', \"Label\"])]\n",
    "    Test_Predictor_Vars.index = range(len(Test_Predictor_Vars))\n",
    "\n",
    "    Validation_Target_Var = Validation_DataSet.loc[:, Validation_DataSet.columns == \"Label\"]\n",
    "    Validation_Target_Var.index = range(len(Validation_Target_Var))\n",
    "    Validation_Predictor_Vars = Validation_DataSet.loc[:,\n",
    "                                Validation_DataSet.columns.drop(['CENTER', 'Gleason', \"Label\"])]\n",
    "    Validation_Predictor_Vars.index = range(len(Validation_Predictor_Vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *** This program and the respective minimum Redundancy Maximum Relevance (mRMR) \n",
      "     algorithm were developed by Hanchuan Peng <hanchuan.peng@gmail.com>for\n",
      "     the paper \n",
      "     \"Feature selection based on mutual information: criteria of \n",
      "      max-dependency, max-relevance, and min-redundancy,\"\n",
      "      Hanchuan Peng, Fuhui Long, and Chris Ding, \n",
      "      IEEE Transactions on Pattern Analysis and Machine Intelligence,\n",
      "      Vol. 27, No. 8, pp.1226-1238, 2005.\n",
      "\n",
      "\n",
      "*** MaxRel features ***\n",
      "Order \t Fea \t Name \t Score\n",
      "1 \t 23 \t DIS_ExcessKurtosis \t 0.142\n",
      "2 \t 22 \t DIS_Kurtosis \t 0.142\n",
      "3 \t 7 \t SUV_Q3 \t 0.137\n",
      "4 \t 56 \t NGLDM_Contrast \t 0.125\n",
      "5 \t 2 \t SUV_mean \t 0.122\n",
      "6 \t 50 \t GLRLM_LRLGE \t 0.110\n",
      "7 \t 64 \t GLZLM_LZLGE \t 0.107\n",
      "\n",
      "*** mRMR features *** \n",
      "Order \t Fea \t Name \t Score\n",
      "1 \t 23 \t DIS_ExcessKurtosis \t 0.142\n",
      "2 \t 46 \t GLRLM_LGRE \t 4.459\n",
      "3 \t 66 \t GLZLM_GLNU \t 2.746\n",
      "4 \t 12 \t SUV_peakSphere0.5mL.1 \t 2.645\n",
      "5 \t 25 \t DIS_peakSphere1mL \t 1.377\n",
      "6 \t 7 \t SUV_Q3 \t 1.386\n",
      "7 \t 29 \t DIS_HISTO_Energy \t 1.008\n"
     ]
    }
   ],
   "source": [
    "#1 MRMR Feature Selection\n",
    "\n",
    "Normalized_Train_Data = pandas.DataFrame(\n",
    "        preprocessing.StandardScaler().fit_transform(Train_Predictor_Vars),\n",
    "        columns=Train_Predictor_Vars.columns)\n",
    "Normalized_Train_Data = pandas.concat([Train_Target_Var, Normalized_Train_Data], axis=1)\n",
    "MRMR_Selected_Features = pymrmr.mRMR(Normalized_Train_Data, 'MIQ', 7)\n",
    "Train_Data_MRMR_Selected_Features = Train_Predictor_Vars[MRMR_Selected_Features]\n",
    "Test_Data_MRMR_Selected_Features = Test_Predictor_Vars[MRMR_Selected_Features]\n",
    "Validation_Data_MRMR_Selected_Features = Validation_Predictor_Vars[MRMR_Selected_Features]\n",
    "Scaler = preprocessing.StandardScaler()\n",
    "Scaler.fit(Train_Data_MRMR_Selected_Features)\n",
    "Normalized_Train_Data_MRMR_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Train_Data_MRMR_Selected_Features),\n",
    "        columns=Train_Data_MRMR_Selected_Features.columns)\n",
    "Normalized_Test_Data_MRMR_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Test_Data_MRMR_Selected_Features),\n",
    "        columns=Test_Data_MRMR_Selected_Features.columns)\n",
    "Normalized_Validation_Data_MRMR_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Validation_Data_MRMR_Selected_Features),\n",
    "        columns=Validation_Data_MRMR_Selected_Features.columns)\n",
    "Folder = Path(file).stem + '//MRMR'\n",
    "Directory = os.getcwd()\n",
    "if (os.path.exists(os.path.join(Directory, Folder)) is False):\n",
    "        os.mkdir(os.path.join(Directory, Folder))\n",
    "Train_Data_MRMR_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Train_MRMR.csv',\n",
    "        index=False, header=True)\n",
    "Test_Data_MRMR_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Test_MRMR.csv',\n",
    "        index=False, header=True)\n",
    "Validation_Data_MRMR_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Validation_MRMR.csv',\n",
    "        index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 ANOVA Features Selection\n",
    "df = MultiCollinearityEliminator(Train_Predictor_Vars, 0.9)\n",
    "skb=SelectKBest(f_classif, k=7).fit(df, numpy.ravel(Train_Target_Var)).get_support(1)\n",
    "ANOVA_Selected_Features = list(df.columns[skb])\n",
    "Train_Data_ANOVA_Selected_Features = Train_DataSet[ANOVA_Selected_Features]\n",
    "Test_Data_ANOVA_Selected_Features = Test_DataSet[ANOVA_Selected_Features]\n",
    "Validation_Data_ANOVA_Selected_Features = Validation_DataSet[ANOVA_Selected_Features]\n",
    "Scaler = preprocessing.StandardScaler()\n",
    "Scaler.fit(Train_Data_ANOVA_Selected_Features)\n",
    "Normalized_Train_Data_ANOVA_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Train_Data_ANOVA_Selected_Features),\n",
    "        columns=Train_Data_ANOVA_Selected_Features.columns)\n",
    "Normalized_Test_Data_ANOVA_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Test_Data_ANOVA_Selected_Features),\n",
    "        columns=Test_Data_ANOVA_Selected_Features.columns)\n",
    "Normalized_Validation_Data_ANOVA_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Validation_Data_ANOVA_Selected_Features),\n",
    "        columns=Validation_Data_ANOVA_Selected_Features.columns)\n",
    "Folder = Path(file).stem + '//ANOVA'\n",
    "Directory = os.getcwd()\n",
    "if (os.path.exists(os.path.join(Directory, Folder)) is False):\n",
    "        os.mkdir(os.path.join(Directory, Folder))\n",
    "Train_Data_ANOVA_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Train_ANOVA.csv',\n",
    "        index=False, header=True)\n",
    "Test_Data_ANOVA_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Test_ANOVA.csv',\n",
    "        index=False, header=True)\n",
    "Validation_Data_ANOVA_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Validation_ANOVA.csv',\n",
    "        index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005640439771781853\n",
      "0.00016361406665971886\n",
      "0.0017645622392370329\n",
      "0.009036071341573668\n",
      "0.03155703142714589\n"
     ]
    }
   ],
   "source": [
    "#3 KruskalWallis Features Selection\n",
    "df = MultiCollinearityEliminator(Train_Predictor_Vars, 0.9)\n",
    "New_Train_DataSet = pandas.concat([Train_Target_Var, df], axis=1)\n",
    "\n",
    "label, idx = np.unique(New_Train_DataSet['Label'], return_inverse=True)\n",
    "\n",
    "# make a list of arrays containing the y-values corresponding to each unique label\n",
    "New_Train_DataSet.drop(\"Label\", inplace=True, axis=1)\n",
    "# use `*` to unpack the list as a sequence of arguments to `stats.kruskal`\n",
    "KruskalWallis_Selected_Features = []\n",
    "for predictor in range(New_Train_DataSet.shape[1]):\n",
    "        groups = [New_Train_DataSet.iloc[:, predictor][idx == i] for i, l in enumerate(label)]\n",
    "        if (stats.kruskal(*groups).pvalue < 0.05):\n",
    "            print(stats.kruskal(*groups).pvalue)\n",
    "            KruskalWallis_Selected_Features.append(New_Train_DataSet.iloc[:, predictor].name)\n",
    "if len(KruskalWallis_Selected_Features)<1:\n",
    "        KruskalWallis_Selected_Features = []\n",
    "        for predictor in range(New_Train_DataSet.shape[1]):\n",
    "            groups = [New_Train_DataSet.iloc[:, predictor][idx == i] for i, l in enumerate(label)]\n",
    "            if (stats.kruskal(*groups).pvalue.pvalue < 0.2):\n",
    "                KruskalWallis_Selected_Features.append(New_Train_DataSet.iloc[:, predictor].name)\n",
    "       \n",
    "Train_Data_KruskalWallis_Selected_Features = Train_DataSet[KruskalWallis_Selected_Features]\n",
    "Test_Data_KruskalWallis_Selected_Features = Test_DataSet[KruskalWallis_Selected_Features]\n",
    "Validation_Data_KruskalWallis_Selected_Features = Validation_DataSet[KruskalWallis_Selected_Features]\n",
    "Scaler = preprocessing.StandardScaler()\n",
    "Scaler.fit(Train_Data_KruskalWallis_Selected_Features)\n",
    "Normalized_Train_Data_KruskalWallis_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Train_Data_KruskalWallis_Selected_Features),\n",
    "        columns=Train_Data_KruskalWallis_Selected_Features.columns)\n",
    "Normalized_Test_Data_KruskalWallis_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Test_Data_KruskalWallis_Selected_Features),\n",
    "        columns=Test_Data_KruskalWallis_Selected_Features.columns)\n",
    "Normalized_Validation_Data_KruskalWallis_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Validation_Data_KruskalWallis_Selected_Features),\n",
    "        columns=Validation_Data_KruskalWallis_Selected_Features.columns)\n",
    "Folder = Path(file).stem + '//KruskalWallis'\n",
    "Directory = os.getcwd()\n",
    "if (os.path.exists(os.path.join(Directory, Folder)) is False):\n",
    "        os.mkdir(os.path.join(Directory, Folder))\n",
    "Train_Data_KruskalWallis_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Train_KruskalWallis.csv',\n",
    "        index=False, header=True)\n",
    "Test_Data_KruskalWallis_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Test_KruskalWallis.csv',\n",
    "        index=False, header=True)\n",
    "Validation_Data_KruskalWallis_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Validation_KruskalWallis.csv',\n",
    "        index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Relief Feature selection\n",
    "df = MultiCollinearityEliminator(Train_Predictor_Vars, 0.90)\n",
    "Relief_Feature_Selection = ReliefF(n_neighbors=20)\n",
    "Relief_Feature_Selection.fit(df.to_numpy(), numpy.ravel(Train_Target_Var))\n",
    "Ten_Top_Features_list = list(Relief_Feature_Selection.top_features)[0:10]\n",
    "Train_Data_Relief_Selected_Features = Train_Predictor_Vars.iloc[:, Ten_Top_Features_list]\n",
    "Test_Data_Relief_Selected_Features = Test_Predictor_Vars.iloc[:, Ten_Top_Features_list]\n",
    "Validation_Data_Relief_Selected_Features = Validation_Predictor_Vars.iloc[:, Ten_Top_Features_list]\n",
    "Scaler = preprocessing.StandardScaler()\n",
    "Scaler.fit(Train_Data_Relief_Selected_Features)\n",
    "Normalized_Train_Data_Relief_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Train_Data_Relief_Selected_Features),\n",
    "        columns=Train_Data_Relief_Selected_Features.columns)\n",
    "Normalized_Test_Data_Relief_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Test_Data_Relief_Selected_Features),\n",
    "        columns=Test_Data_Relief_Selected_Features.columns)\n",
    "Normalized_Validation_Data_Relief_Selected_Features = pandas.DataFrame(\n",
    "        Scaler.transform(Validation_Data_Relief_Selected_Features),\n",
    "        columns=Validation_Data_Relief_Selected_Features.columns)\n",
    "Folder = Path(file).stem + '//Relief'\n",
    "Directory = os.getcwd()\n",
    "if (os.path.exists(os.path.join(Directory, Folder)) is False):\n",
    "        os.mkdir(os.path.join(Directory, Folder))\n",
    "Train_Data_Relief_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Train_Relief.csv',\n",
    "        index=False, header=True)\n",
    "Test_Data_Relief_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Test_Relief.csv',\n",
    "        index=False, header=True)\n",
    "Validation_Data_Relief_Selected_Features.to_csv(\n",
    "        f'{Directory}//{Folder}//{Path(file).stem}_Validation_Relief.csv',\n",
    "        index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: Logistic Regression, Linear Discriminant Analysis, Extra Trees,Random Forest, K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold CrossValidation\n",
    "CV = StratifiedKFold(n_splits=5, shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "#1 Logistic Regression classifire\n",
    "Logit_Algorithm = LogisticRegression(random_state=2)\n",
    "Logit_Params_Space = dict()\n",
    "Logit_Params_Space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "Logit_Algorithm = GridSearchCV(Logit_Algorithm, Logit_Params_Space, cv=CV, scoring='accuracy', n_jobs=NCPU)\n",
    "\n",
    "\n",
    "\n",
    "#2 Linear Discriminant Analysis\n",
    "LDA_Algorithm = LinearDiscriminantAnalysis()\n",
    "\n",
    "#3 ExtraTree\n",
    "ExtraTree_Algorithm = ExtraTreeClassifier(random_state=0)\n",
    "ExtraTree_params_space = dict()\n",
    "ExtraTree_params_space['criterion'] = ['gini', 'entropy']\n",
    "ExtraTree_params_space['max_depth'] = [6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "ExtraTree_params_space['min_samples_split'] = [4, 6, 8, 10]\n",
    "ExtraTree_params_space['max_features'] = ['sqrt', 5, 6, 8,10]\n",
    "ExtraTree_Algorithm = RandomizedSearchCV(ExtraTree_Algorithm, ExtraTree_params_space, cv=CV, n_iter=150,\n",
    "                                             scoring='accuracy', n_jobs=NCPU)\n",
    "\n",
    "\n",
    "\n",
    "#4 RandomForest\n",
    "RF_Algorithm = RandomForestClassifier(random_state=3)\n",
    "RF_params_space = dict()\n",
    "RF_params_space['n_estimators'] = numpy.arange(50, 500, 50)\n",
    "RF_params_space['criterion'] = ['gini', 'entropy']\n",
    "RF_params_space['max_depth'] = [6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "RF_params_space['min_samples_split'] = [4, 6, 8, 10]\n",
    "RF_params_space['max_samples'] = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "RF_params_space['max_features'] = ['sqrt', 5, 6, 8]\n",
    "RF_Algorithm = RandomizedSearchCV(RF_Algorithm, RF_params_space, cv=CV, n_iter=150, scoring='accuracy', n_jobs=NCPU)\n",
    "    \n",
    "\n",
    "#5 k-nearest neighbors\n",
    "KNN_Algorithm = KNeighborsClassifier()\n",
    "KNN_params_space = dict()\n",
    "KNN_params_space['n_neighbors'] = [3, 5, 7, 9]\n",
    "KNN_params_space['weights'] = ['uniform', 'distance']\n",
    "KNN_params_space['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "KNN_Algorithm = RandomizedSearchCV(KNN_Algorithm, KNN_params_space, cv=CV, n_iter=30, scoring='accuracy', n_jobs=NCPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models_List & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models_List = \\\n",
    "        [\n",
    "            'RF_MRMR', 'RF_ANOVA', 'RF_KruskalWallis', 'RF_Relief',\n",
    "\n",
    "            'LDA_MRMR', 'LDA_ANOVA', 'LDA_KruskalWallis',  'LDA_Relief',\n",
    "\n",
    "            'KNN_MRMR', 'KNN_ANOVA', 'KNN_KruskalWallis',  'KNN_Relief',\n",
    "           \n",
    "            'Logit_MRMR', 'Logit_ANOVA', 'Logit_KruskalWallis','Logit_Relief',\n",
    "\n",
    "            'ExtraTree_MRMR', 'ExtraTree_ANOVA', 'ExtraTree_KruskalWallis', 'ExtraTree_Relief',    \n",
    "        ]\n",
    "Metrics_list = [ \"auc\",\"accuracy\",\"precision\",\"recall\",\"f1score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates DataFrames to store performance metrics (AUC, accuracy, precision, recall, F1 score) \n",
    "\n",
    "Train_Results_Matrix = pandas.DataFrame(columns=['model', \"auc\",\"accuracy\",\"precision\",\"recall\",\"f1score\"],index=range(20))\n",
    "Train_Results_Matrix.iloc[:, 0] = Models_List\n",
    "\n",
    "Test_Results_Matrix = Train_Results_Matrix.copy()\n",
    "Test_Results_Matrix.iloc[:, 0] = Models_List\n",
    "\n",
    "Validation_Results_Matrix = Train_Results_Matrix.copy()\n",
    "Validation_Results_Matrix.iloc[:, 0] = Models_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_MRMR\n",
      "RF_ANOVA\n",
      "RF_KruskalWallis\n",
      "RF_Relief\n",
      "LDA_MRMR\n",
      "LDA_ANOVA\n",
      "LDA_KruskalWallis\n",
      "LDA_Relief\n",
      "KNN_MRMR\n",
      "KNN_ANOVA\n",
      "KNN_KruskalWallis\n",
      "KNN_Relief\n",
      "Logit_MRMR\n",
      "Logit_ANOVA\n",
      "Logit_KruskalWallis\n",
      "Logit_Relief\n",
      "ExtraTree_MRMR\n",
      "ExtraTree_ANOVA\n",
      "ExtraTree_KruskalWallis\n",
      "ExtraTree_Relief\n"
     ]
    }
   ],
   "source": [
    "# 1. Algoritm_Dict - associates various machine learning algorithms \n",
    "Algoritm_Dict = dict()\n",
    "Algoritm_Dict[\"RF\"] = RF_Algorithm\n",
    "Algoritm_Dict[\"LDA\"] = LDA_Algorithm\n",
    "Algoritm_Dict[\"KNN\"] = KNN_Algorithm\n",
    "Algoritm_Dict[\"Logit\"] = Logit_Algorithm\n",
    "Algoritm_Dict[\"ExtraTree\"] = ExtraTree_Algorithm\n",
    "\n",
    "\n",
    "# 2. Features_Dict - organizes selected features from different feature selection methods \n",
    "Features_Dict = dict()\n",
    "Features_Dict[\"MRMR\"] = \\\n",
    "        {\"Train\": Normalized_Train_Data_MRMR_Selected_Features,\n",
    "         \"Test\": Normalized_Test_Data_MRMR_Selected_Features,\n",
    "         \"Validation\": Normalized_Validation_Data_MRMR_Selected_Features}\n",
    "Features_Dict[\"ANOVA\"] = \\\n",
    "        {\"Train\": Normalized_Train_Data_ANOVA_Selected_Features,\n",
    "         \"Test\": Normalized_Test_Data_ANOVA_Selected_Features,\n",
    "         \"Validation\": Normalized_Validation_Data_ANOVA_Selected_Features}\n",
    "Features_Dict[\"KruskalWallis\"] = \\\n",
    "        {\"Train\": Normalized_Train_Data_KruskalWallis_Selected_Features,\n",
    "         \"Test\": Normalized_Test_Data_KruskalWallis_Selected_Features,\n",
    "         \"Validation\": Normalized_Validation_Data_KruskalWallis_Selected_Features}\n",
    "Features_Dict[\"Relief\"] = \\\n",
    "        {\"Train\": Normalized_Train_Data_Relief_Selected_Features,\n",
    "         \"Test\": Normalized_Test_Data_Relief_Selected_Features,\n",
    "         \"Validation\": Normalized_Validation_Data_Relief_Selected_Features}\n",
    "   \n",
    "Folder = Path(file).stem \n",
    "for model, i in zip(Models_List, range(len(Models_List))):\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/max/Documents/Classification/Data/WP//GA-PSMA_Multicentric(WP)//Relief//GA-PSMA_Multicentric(WP)_ExtraTree_Relief.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Splits the 'model' variable into two parts: the algorithm name and feature selection method.\n",
    "Algoritm, Feature_Selection = model.split('_')\n",
    "# 2. Retrieves the corresponding algorithm from Algoritm_Dict and selected features from Features_Dict.\n",
    "BaseAlgorithm = Algoritm_Dict[f'{Algoritm}']\n",
    "Features = Features_Dict[f'{Feature_Selection}']\n",
    "# 3. Fits the selected machine learning algorithm to the training features and target variable.\n",
    "Final_Model = BaseAlgorithm.fit(Features[\"Train\"], Train_Target_Var.values.ravel())\n",
    "# 4. Saves the trained model as a pickle file in a specified directory, incorporating the feature selection method and model name into the filename.\n",
    "joblib.dump(Final_Model,  f'{Directory}//{Folder}//{Feature_Selection}//'+Path(file).stem+'_'+model+'.pkl', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Confusion matrix, without normalization\n"
     ]
    }
   ],
   "source": [
    "# Predict the probabilities for the training dataset\n",
    "y_pred_train = Final_Model.predict_proba(Features[\"Train\"])\n",
    "\n",
    "# Plot the confusion matrix for the test dataset\n",
    "plot_confusion_matrix(Test_Target_Var.values,Final_Model.predict(Features[\"Test\"]),classes=n_classes, dataset='Test')\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the AUC for the training dataset\n",
    "auc_train_micro=roc_plot(y_true=Train_Target_Var,y_score=y_pred_train[:,1],dataset='Train')\n",
    "Train_Results_Matrix.iloc[i, 1] = auc_train_micro\n",
    "\n",
    "\n",
    "# Generate the classification report for the test dataset    \n",
    "cr_test=classification_report( Test_Target_Var.values,Final_Model.predict(Features[\"Test\"]) ,target_names=n_classes)\n",
    "\n",
    "# Save the classification report to a text file\n",
    "with open(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_Test.txt', 'w') as f:\n",
    "            f.write(cr_test)\n",
    "\n",
    "# Predict the probabilities for the test dataset\n",
    "y_pred_test = Final_Model.predict_proba(Features[\"Test\"])\n",
    "\n",
    "# Calculate the AUC for the test dataset\n",
    "auc_test_micro=roc_plot(y_true=Test_Target_Var,y_score=y_pred_test[:,1],dataset='Test')\n",
    "Test_Results_Matrix.iloc[i, 1] = auc_test_micro\n",
    "\n",
    "# Save the test predictions to a CSV file\n",
    "y_pred_test_s=pandas.DataFrame(y_pred_test)\n",
    "y_pred_test_s.to_csv(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_Test.csv')\n",
    "\n",
    "# Predict the probabilities for the validation dataset\n",
    "y_pred_valid = Final_Model.predict_proba(Features[\"Validation\"])\n",
    "\n",
    "# Plot the confusion matrix for the validation dataset\n",
    "plot_confusion_matrix(Validation_Target_Var.values,Final_Model.predict(Features[\"Validation\"]) ,classes= n_classes, dataset='Validation')\n",
    "\n",
    "# Generate the classification report for the validation dataset\n",
    "cr_valid=classification_report( Validation_Target_Var.values,Final_Model.predict(Features[\"Validation\"]) ,target_names=n_classes)\n",
    "\n",
    "# Save the classification report to a text file\n",
    "with open(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_Validation.txt', 'w') as f:\n",
    "            f.write(cr_valid)\n",
    "auc_valid_micro=roc_plot(y_true=Validation_Target_Var,y_score=y_pred_valid[:,1],dataset='Validation')\n",
    "\n",
    "# Save the validation predictions to a CSV file\n",
    "y_pred_valid_s=pandas.DataFrame(y_pred_valid)\n",
    "y_pred_valid_s.to_csv(f'{Directory}//{Folder}//{Feature_Selection}//{Path(file).stem}_{model}_Validation.csv')\n",
    "\n",
    "\n",
    "# Store evaluation metrics for training, test, and validation\n",
    "Validation_Results_Matrix.iloc[i, 1] =auc_valid_micro\n",
    "Train_Results_Matrix.iloc[i, 2] = accuracy_score(Train_Target_Var, Final_Model.predict(Features[\"Train\"]))\n",
    "Test_Results_Matrix.iloc[i, 2] = accuracy_score(Test_Target_Var, Final_Model.predict(Features[\"Test\"]))\n",
    "Train_Results_Matrix.iloc[i, 3] = precision_score(Train_Target_Var, Final_Model.predict(Features[\"Train\"]))\n",
    "Test_Results_Matrix.iloc[i, 3] = precision_score(Test_Target_Var, Final_Model.predict(Features[\"Test\"]))\n",
    "Train_Results_Matrix.iloc[i, 4] = recall_score(Train_Target_Var, Final_Model.predict(Features[\"Train\"]))\n",
    "Test_Results_Matrix.iloc[i, 4] = recall_score(Test_Target_Var, Final_Model.predict(Features[\"Test\"]))\n",
    "Train_Results_Matrix.iloc[i, 5] = f1_score(Train_Target_Var, Final_Model.predict(Features[\"Train\"]))\n",
    "Test_Results_Matrix.iloc[i, 5] = f1_score(Test_Target_Var, Final_Model.predict(Features[\"Test\"]))\n",
    "\n",
    "\n",
    "# Store evaluation metrics for the validation dataset     \n",
    "Validation_Results_Matrix.iloc[i, 2] = accuracy_score(Validation_Target_Var, Final_Model.predict(Features[\"Validation\"]))\n",
    "Validation_Results_Matrix.iloc[i, 3] = precision_score(Validation_Target_Var, Final_Model.predict(Features[\"Validation\"]))\n",
    "Validation_Results_Matrix.iloc[i, 4] = recall_score(Validation_Target_Var, Final_Model.predict(Features[\"Validation\"]))\n",
    "Validation_Results_Matrix.iloc[i, 5] = f1_score(Validation_Target_Var, Final_Model.predict(Features[\"Validation\"]))\n",
    "\n",
    "\n",
    "# Save the results matrices to CSV files\n",
    "Train_Results_Matrix.to_csv(f'{os.getcwd()}//{Path(file).stem}//Train_Results.csv', index=False, header=True)\n",
    "Test_Results_Matrix.to_csv(f'{os.getcwd()}//{Path(file).stem}//Test_Results.csv', index=False, header=True)\n",
    "Validation_Results_Matrix.to_csv(f'{os.getcwd()}//{Path(file).stem}//Validation_Results.csv', index=False, header=True)\n",
    "\n",
    "# Add a column indicating the dataset name\n",
    "Train_Results_Matrix.insert(loc=0, column='set', value=Path(file).stem)\n",
    "Test_Results_Matrix.insert(loc=0, column='set', value=Path(file).stem)\n",
    "Validation_Results_Matrix.insert(loc=0, column='set', value=Path(file).stem)\n",
    "\n",
    "\n",
    "# Concatenate the results matrices for all datasets\n",
    "Train_Results_Matrix_all=pandas.concat([Train_Results_Matrix_all,Train_Results_Matrix], axis=0)\n",
    "Test_Results_Matrix_all=pandas.concat([Test_Results_Matrix_all,Test_Results_Matrix], axis=0)\n",
    "Validation_Results_Matrix_all=pandas.concat([Validation_Results_Matrix_all,Validation_Results_Matrix], axis=0)\n",
    "\n",
    "# Save the concatenated results matrices to CSV files\n",
    "Train_Results_Matrix_all.to_csv('Train_Results.csv', index=False, header=True)\n",
    "Test_Results_Matrix_all.to_csv('Test_Results.csv', index=False, header=True)\n",
    "Validation_Results_Matrix_all.to_csv('Validation_Results.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mykernel)",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
